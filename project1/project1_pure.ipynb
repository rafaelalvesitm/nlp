{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 1\n",
    "\n",
    "Escolher qualquer corpus (conjunto de documentos) ou livro de até 100 MB\n",
    "em português e extrair as seguintes informaçoes:\n",
    "\n",
    "- Quantidade de palavras distintas;\n",
    "- Histograma das palavras;\n",
    "- Histograma de prefixos de tamanho (1,2,3,4 e 5)\n",
    "- Histograma de sufixos de tamanho (1,2,3,4 e 5)\n",
    "\n",
    "O Corpus pode ser encontrado na pasta Corpus do projeto 1.\n",
    "\n",
    "# Observação\n",
    "\n",
    "O código abaixo foi escrito apenas com python 3 e as bibliotecas \"os\" para ler arquivos de uma pasta e \"matlotlib\" para criar o gráfico de frequências de palavras.\n",
    "\n",
    "Para observar o relatório elaborado com base neste projeto confira a página no meu site pessoal: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filepaths(path):\n",
    "    '''\n",
    "    Loads all the filepaths in a directory into a list\n",
    "    path: path to the directory\n",
    "    '''\n",
    "    filepaths = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                filepaths.append(os.path.join(root, filename))\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(filepath):\n",
    "    '''\n",
    "    Opens a text file and reads its data\n",
    "    filepath: path to the text file\n",
    "    '''\n",
    "    with open(filepath, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    '''\n",
    "    Splits the text into a list of words in lowercase\n",
    "    text: text to be split\n",
    "    '''\n",
    "    words = text.split()\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_words(words):\n",
    "    '''\n",
    "    Count the number of times each word appears in a list of words\n",
    "    words: list of words\n",
    "    '''\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(word_counts, filename):\n",
    "    '''\n",
    "    Plots a histogram of the word counts\n",
    "    word_counts: list of word counts\n",
    "    filename: name of the file to be in the title the histogram\n",
    "    '''\n",
    "    word_counts.reverse() # Reverse the list to present the most common word first \n",
    "    words, counts = zip(*word_counts)\n",
    "    plt.barh(words, counts)\n",
    "    plt.title(filename + \"\\n Word Frequency\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Word\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_letter_prefix(words, n):\n",
    "    '''\n",
    "    Get the n-letter prefixes of a list of words\n",
    "    words: list of words\n",
    "    n: number of letters in the prefix\n",
    "    '''\n",
    "    prefixes = []\n",
    "    for word in words:\n",
    "        if not len(word[0:n]) < n:\n",
    "            prefixes.append(word[0:n])\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_letter_sufix(words, n):\n",
    "    '''\n",
    "    Get the n-letter sufixes of a list of words\n",
    "    words: list of words\n",
    "    n: number of letters in the sufixes\n",
    "    '''\n",
    "    prefixes = []\n",
    "    for word in words:\n",
    "        if not len(word[-n:]) < n:\n",
    "            prefixes.append(word[-n:])\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the whole corpus and create a list of words\n",
    "text = \"\"\n",
    "for file in filepaths:\n",
    "    text += read_txt(file)\n",
    "words = split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the word frequency and word for the top 20 words that appears in ethe whole corpus\n",
    "plot_histogram(count_words(words)[0:20], \"Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the word frequency and word for the top 20 n-letter prefixes that appears in ethe whole corpus\n",
    "for i in range(1,6):\n",
    "    prefixes = get_n_letter_prefix(words, i)\n",
    "    prefixes = count_words(prefixes)[0:20]\n",
    "    plot_histogram(prefixes, f\"Corpus | {i}-letter prefixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the word frequency and word for the top 20 n-letter sufixes that appears in ethe whole corpus\n",
    "for i in range(1,6):\n",
    "    sufixes = get_n_letter_sufix(words, i)\n",
    "    sufixes = count_words(sufixes)[0:20]\n",
    "    plot_histogram(sufixes, f\"Corpus | {i}-letter prefixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the word frequency and word for the top 20 words that appears in each document in the corpus\n",
    "filepaths = load_filepaths(\"./corpus\")\n",
    "for file in filepaths:\n",
    "    text = read_txt(file)\n",
    "    words = split_text(text)\n",
    "    words = count_words(words)[0:20]\n",
    "    words.reverse()\n",
    "    filename = os.path.basename(file).rsplit('.', 1)[0]\n",
    "    plot_histogram(words, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
